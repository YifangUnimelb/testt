---
title: "Forecasting Inflation and Interest Rate in Australia"
author: "Yifang"

execute:
  echo: false
  
bibliography: references.bib
---

> **Abstract.** This paper forecasts Australian inflation and interest rate using Bayesian Vector Regressive Model with Stochastic Volatility and a multivariate-t distributed error, with the purpose of allowing time varying volatility and capturing sudden increase in volatility during extreme period such as COVID-19.It is an application of such method, which is suggested as a significant improvement over a standard BVAR, to the Australian macroeconomic variables to generate spot and density forecast using post-COVID data.

> **Keywords.** BVARs, Stochastic Volatility, t-distributed error, inflation, interest rate, Australian economy

# Introduction

**Objective:** This paper aims to forecast Australian short term interest rate and inflation. It follows the method in Hartwig(2022), using a BVAR-SV model with its error covariance matrix being multivariate-t distribution.

**Question:** Can the model suggested produce reliable spot and density forecast for Australian inflation and interest rate?

**Motivation:** Volatility variation across time in macroeconomic variables is widely explored in literature(Bloom,2014), which the standard Gaussian error modeling may fail to capture and then leads to unreliable results. Hartwig(2022) suggests that several BVAR models with modified volatility distribution which differentiate from the standard Gaussian perform better under likelihood measurement. The best fitting one with post-COVID19 data is BVAR-t-SV. The stochastic process captures the time persistence of volatility, which is evident in variables such as short term interest rate(Ball and Torous,1999). A multivariate-t distributed error, with relatively fatter tails, can recognize some extreme volatility as temporary spikes instead of persistent effect. The forecast focus on inflation and interest rate due to their strong relevance to policy making and people's daily lives. Many challenges arise post-COVID for government to facilitate the revitalization of the economy, where forecast plays its roles.

# Data

All data is obtained from the RBA. Daily or monthly data is converted to quarterly format by averaging. Following Chan(2017, other than cash rate and unemployment, variables will be transformed using log difference times 400 in BVAR. These are some standard variables to include in a macroeconomics forecast:

**Cash rate:** the cash rate target in percent (series_id:FIRMMCRTD)

**Money aggregate(M1):** the seasonal adjusted M1 aggregate in \$billion (series_id:DMAM1S)

**Money aggregate(M3):** the seasonal adjusted M3 aggregate in \$billion (series_id:DMAM3S)

**Consumer Price Index** Consumer Price Index (series_id:GCPIAG)

**Real GDP:** Gross Domestic Product in real terms in \$million (series_id:GGDPCVGDP)

**Unemployment:** Unemployment rate in percent (series_id:GLFSUPSA)

The data window covers 1990 Q1 to 2023 Q4, as the most up-to-date post-COVID data in Australia, similar to Hartwig(2022).

```{r read data}
#| echo: false
#| message: false
#| warning: false

library(readrba)

un_em = read_rba(series_id = "GLFSURSA") 
gdp = read_rba(series_id = "GGDPCVGDP")
cpi = read_rba(series_id = "GCPIAG") 

cr = read_rba(series_id = "FIRMMCRTD")

m1 = read_rba(series_id = "DMAM1S") 
m3 = read_rba(series_id = "DMAM3S") 

library(dplyr)
library(lubridate)

cpi <- cpi %>% filter(date > as.Date("1989-12-31"))
gdp <- gdp %>% filter(date > as.Date("1989-12-31"))
m1 <- m1 %>% filter(date > as.Date("1989-12-31"))
m3 <- m3 %>% filter(date > as.Date("1989-12-31"))
un_em <- un_em %>% filter(date > as.Date("1989-12-31"))

cpi <- cpi %>% filter(date < as.Date("2024-01-01"))
gdp <- gdp %>% filter(date < as.Date("2024-01-01"))
m1 <- m1 %>% filter(date < as.Date("2024-01-01"))
m3 <- m3 %>% filter(date < as.Date("2024-01-01"))
un_em <- un_em %>% filter(date < as.Date("2024-01-01"))

m1 <- m1 %>%
  mutate(Quarter = paste(year(date), quarter(date), sep = "Q")) %>%
  group_by(Quarter) %>%
  summarize(Average = mean(value, na.rm = TRUE))

m3 <- m3 %>%
  mutate(Quarter = paste(year(date), quarter(date), sep = "Q")) %>%
  group_by(Quarter) %>%
  summarize(Average = mean(value, na.rm = TRUE))

un_em <- un_em %>%
  mutate(Quarter = paste(year(date), quarter(date), sep = "Q")) %>%
  group_by(Quarter) %>%
  summarize(Average = mean(value, na.rm = TRUE))

cr <- cr %>%
  mutate(Quarter = paste(year(date), quarter(date), sep = "Q")) %>%
  group_by(Quarter) %>%
  summarize(Average = mean(value, na.rm = TRUE))

cr <- cr %>% filter(Quarter != "2024Q1")
cr <- cr %>% filter(Quarter != "2024Q2")


```

```{r create data matrix}
#| echo: false
#| message: false
#| warning: false

library(dplyr)

# Assuming tibble1, tibble2, tibble3 are your tibbles
# and you want columnA from tibble1, columnB from tibble2
data <- bind_cols(
  cpi %>% select(date),
  cpi %>% select(value),
  cr %>% select(Average),
  gdp %>% select(value),
  m1 %>% select(Average),
  m3 %>% select(Average),
  un_em %>% select(Average)# Add as many as needed
)

data <- data %>% rename(cpi = value...2, cr = Average...3, gdp = value...4, m1 = Average...5, m3 = Average...6, un_em = Average...7)

data_trans <- data %>%
  mutate(cpi_log = c(NA, 400*diff(log(cpi))), gdp_log =c(NA, 400*diff(log(gdp))), m1_log =c(NA, 400*diff(log(m1))), m3_log =c(NA, 400*diff(log(m3))))

data_trans <- data_trans %>% select(date, cpi_log, gdp_log, m1_log, m3_log, cr, un_em)
```

## Time Series Plot

```{r load package}
#| echo: false
#| message: false
#| warning: false

library(ggplot2)
library(patchwork)

theme_set(theme_bw())

pcpi <- ggplot(data, aes(date,cpi)) + geom_line(size = 0.25)+labs(title = "CPI") +
  theme(plot.title = element_text(size = 10),
        axis.title.x = element_text(size = 8),
        axis.title.y = element_text(size = 8))

pgdp <- ggplot(data, aes(date,gdp)) + geom_line(size = 0.25)+labs(title = "GDP") +
  theme(plot.title = element_text(size = 10),
        axis.title.x = element_text(size = 8),
        axis.title.y = element_text(size = 8))


pm1 <- ggplot(data, aes(date,m1)) +geom_line(size = 0.25)+labs(title = "M1") +
  theme(plot.title = element_text(size = 10),
        axis.title.x = element_text(size = 8),
        axis.title.y = element_text(size = 8))

pm3 <- ggplot(data, aes(date,m3)) + geom_line(size = 0.25)+labs(title = "M3") +
  theme(plot.title = element_text(size = 10),
        axis.title.x = element_text(size = 8),
        axis.title.y = element_text(size = 8))

pcr <- ggplot(data, aes(date,cr)) + geom_line(size = 0.25)+labs(title = "cash rate") +
  theme(plot.title = element_text(size = 10),
        axis.title.x = element_text(size = 8),
        axis.title.y = element_text(size = 8))

pun_em <- ggplot(data, aes(date,un_em)) + geom_line(size = 0.25)+labs(title = "unemployment rate") +
  theme(plot.title = element_text(size = 10),
        axis.title.x = element_text(size = 8),
        axis.title.y = element_text(size = 8))

 
(pcpi + pgdp )/(pm1 + pm3 )/(pcr + pun_em)

```

```{r}
#| echo: false
#| message: false
#| warning: false

library(ggplot2)
library(patchwork)

theme_set(theme_bw())

pcpil <- ggplot(data_trans, aes(date,cpi_log)) + geom_line(size = 0.25)+labs(title = "log difference CPI") +
  theme(plot.title = element_text(size = 10),
        axis.title.x = element_text(size = 8),
        axis.title.y = element_text(size = 8))

pgdpl <- ggplot(data_trans, aes(date,gdp_log)) + geom_line(size = 0.25)+labs(title = "log difference GDP") +
  theme(plot.title = element_text(size = 10),
        axis.title.x = element_text(size = 8),
        axis.title.y = element_text(size = 8))


pm1l <- ggplot(data_trans, aes(date,m1_log)) +geom_line(size = 0.25)+labs(title = "log difference M1") +
  theme(plot.title = element_text(size = 10),
        axis.title.x = element_text(size = 8),
        axis.title.y = element_text(size = 8))

pm3l <- ggplot(data_trans, aes(date,m3_log)) + geom_line(size = 0.25)+labs(title = "log difference M3") +
  theme(plot.title = element_text(size = 10),
        axis.title.x = element_text(size = 8),
        axis.title.y = element_text(size = 8))
 
(pcpil + pgdpl )/(pm1l + pm3l )

```

## ACF and PACF

```{r ACF}
#| echo: false
#| message: false
#| warning: false

library(tidyr)

data_trans <- drop_na(data_trans)

acf(data_trans$cpi_log)
acf(data_trans$gdp_log)
acf(data_trans$m1_log)
acf(data_trans$m3_log)
acf(data_trans$cr)
acf(data_trans$un_em)

```

```{r PACF}
#| echo: false
#| message: false
#| warning: false

library(tidyr)

data_trans <- drop_na(data_trans)

pacf(data_trans$cpi_log)
pacf(data_trans$gdp_log)
pacf(data_trans$m1_log)
pacf(data_trans$m3_log)
pacf(data_trans$cr)
pacf(data_trans$un_em)


```

## Augmented Dickey-Fuller

```{r load package}
#| echo: false
#| message: false
#| warning: false

library(tseries)

adf.test(data_trans$cpi_log)
adf.test(data_trans$gdp_log)
adf.test(data_trans$m1_log)
adf.test(data_trans$m3_log)
adf.test(data_trans$cr)
adf.test(data_trans$un_em)

p_value <- c(0.01796, 0.01, 0.02154, 0.1622, 0.01, 0.3884)
ADF_stats <- c(-3.8653, -5.765, -3.7918,-2.9958, -4.3135,-2.4522)
Variable <- c("CPI_log", "GDP_log","M1_log","M3_log","Cash rate","Unemployment")

adf_res <- cbind(Variable,ADF_stats , p_value)

library(knitr)
library(kableExtra)

kbl(adf_res) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))

```

# Model

Here presents the Bayesian VAR with Stochastic Student-t volatility, the general form of a VAR(p):

$$y_t = a_0 +A_1y_{t-1}+...+A_py_{t-p}+ \epsilon_t $$

where $y_t$ is a $n \times 1$ vector and $n$ is the number of variables. $a_0$ is the $n \times 1$ intercept vector. $A_p$ is $n \times n$ coefficient matrix for each lag order $p$. Put it in compact matrix notation:

$$Y = XA+E$$ where $Y_{T \times n}=(y_1', y_2',...,y_T')'$, $X_{T \times K}=(x_1', x_2',...,x_T')'$. Each $x_{K \times 1}=(1, y_{t-1}',...,y_{t-p}')'$. $A$ is a compact coefficient matrix $A_{K \times n}=(a_0', A_1',...,A_p')'$ and $E_{T \times n}=(\epsilon_1', \epsilon_2',...,\epsilon_T')'$. Note, $K = 1+pn$.

In standard form, the error term is normally distributed $\epsilon_t \sim iidN(0, \Sigma)$, or $E \sim MN(0, \Sigma \otimes I_T)$. $\Sigma$ is a $n \times n$ covariance matrix and $I_T$ is an $T \times T$ identity matrix. In this paper, following Hartwig(2022), I use the specification:

$$\epsilon_t \sim N(0, \Sigma \cdot \lambda_t \cdot exp(h_t))$$

where $\lambda_t \sim IG(\nu/2,\nu/2)$ and $h_t$ follows: $h_t = \rho h_{t-1}+ \epsilon^{h}_{t}$, with $|\rho|< 1$ and $\epsilon^{h}_{t} \sim N(0, \sigma^{2}_h)$. Then the compact distribution of $E \sim MN(0,\Sigma \otimes \Omega)$.

## Bayesian Estimation

# References
